{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e3b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fftpack import ifft2\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# import websocket\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "# import mouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48dd1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startDriver():\n",
    "    driver = webdriver.Chrome(executable_path = r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n",
    "    return driver\n",
    "\n",
    "def getToScreener(driver):\n",
    "    URL = 'file:///C:/Users/mkrhi/OneDrive/Dokumenter/GitHub/Touch-Free-Interaction/Website/index.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def getToDarkness(driver):\n",
    "    URL = 'file:///C:/Users/mkrhi/OneDrive/Dokumenter/GitHub/Touch-Free-Interaction/Website/black.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def clickNumber(number, driver):\n",
    "    button = driver.find_element(By.ID, f'key{number}')\n",
    "    button.click()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    print(message)\n",
    "\n",
    "def power_spectrum(fft):\n",
    "    # Returns the power spectrum of the 2D-Fourier Transform\n",
    "    return np.abs(fft)**2\n",
    "\n",
    "def FFT(image):\n",
    "    # Return the fast fourier transform after it is centered\n",
    "    fft = np.fft.fft2(image, s=None, axes=(-2, -1), norm=None)\n",
    "    fft = np.fft.fftshift(fft, axes=None)\n",
    "    return fft\n",
    "\n",
    "def inverse_FFT(pwr_spectrum):\n",
    "    # Compute the inverse Fourier transform of the power spectrum\n",
    "    fft_array = np.fft.ifftshift(pwr_spectrum, axes=None)\n",
    "    img = ifft2(fft_array)\n",
    "\n",
    "    # Take the real part of the image to remove any imaginary components\n",
    "    img = np.real(img)\n",
    "\n",
    "    # Normalize the pixel values to the range [0, 255]\n",
    "    img = (img - np.min(img)) * (255 / (np.max(img) - np.min(img)))\n",
    "\n",
    "    # Convert the pixel values to integers and return the image\n",
    "    return np.abs(img.astype(np.uint8)) ** 2\n",
    "\n",
    "def maskDots(fft_img, height, width, X, Y, radius_squared):\n",
    "    # Compute the squared distances from the circle center\n",
    "    r1 = (np.arange(height)[:, None] - Y - height/2) ** 2 + (np.arange(width) - X - width/2) ** 2\n",
    "    r2 = (np.arange(height)[:, None] + Y - height/2) ** 2 + (np.arange(width) + X - width/2) ** 2\n",
    "\n",
    "    \n",
    "    # Create a mask that is True where both distances are greater than radius ** 2\n",
    "    mask = np.logical_and(r1 > radius_squared, r2 > radius_squared)\n",
    "\n",
    "    # Apply the mask to the FFT image\n",
    "    fft_img[mask] = 0\n",
    "    \n",
    "    fft_copy = fft_img.copy()\n",
    "\n",
    "    return fft_copy\n",
    "\n",
    "def maskLine(fft_img, height, width, X, Y, radius_squared):\n",
    "    r = []\n",
    "    for i in range(10):\n",
    "        r.append((np.arange(height)[:, None] - Y + (2*Y/10*i) - height/2) ** 2 + (np.arange(width) - X + (2*X/10*i) - width/2) ** 2)\n",
    "        \n",
    "    center = (np.arange(height)[:, None] - height/2) ** 2 + (np.arange(width) - width/2) ** 2\n",
    "    # Create a mask that is True where both distances are greater than radius ** 2\n",
    "    \n",
    "    mask = r[0] > radius_squared\n",
    "    \n",
    "    for i in range(9):\n",
    "        if i not in [3,4,5,6]:\n",
    "            mask = np.logical_and(mask, r[i+1] > radius_squared)\n",
    "\n",
    "    # Apply the mask to the FFT image\n",
    "    fft_img[mask] = 0\n",
    "    \n",
    "    fft_copy = fft_img.copy()\n",
    "\n",
    "    return fft_copy\n",
    "\n",
    "def maskSquare(fft_img, size, X, Y):\n",
    "    X = int(X/2)\n",
    "    Y = int(Y/2)\n",
    "    fft_copy = fft_img[X - size:X + size,Y - size:Y + size].copy()\n",
    "    return fft_copy\n",
    "\n",
    "def mask(fft_img, height, width, X, Y, radius_squared):\n",
    "    return maskDots(fft_img, height, width, X, Y, radius_squared)\n",
    "\n",
    "def planeInteraction(img, x, y):\n",
    "    pressed = False\n",
    "    height, width = len(img), len(img[0])\n",
    "    # print(\"{:2e}\".format(img[round(height/2) + y][round(width/2) + x]), end=\"\\r\")\n",
    "    if img[round(height/2) + y][round(width/2) + x] > 9 * 10 ** 6:\n",
    "        pressed = True\n",
    "    return pressed\n",
    "\n",
    "def keyAreaPressed(img):\n",
    "    # Takes image returns which key is pressed\n",
    "    points = 10 # Number of vertical and horizontal points of a key should be looked at\n",
    "    height, width = len(img)/(3*points + 1), len(img[0])/(3*points + 1) # Determines the vertical and horizontal distance moved\n",
    "        \n",
    "    total = []\n",
    "    for h in range(3):\n",
    "        for w in range(3):\n",
    "            value = 0\n",
    "            for i in range(points):\n",
    "                for j in range(points):\n",
    "                    # Adds the total pixel value of all points in a key\n",
    "                    #value += img[round(height*i + h*height*points + height/2)][round(width*j + (2-w)*width*points + width/2)]\n",
    "                    value += img[round(height*i + h*height*points + height/2)][round(width*j + w*width*points + width/2)]\n",
    "            total += [value]\n",
    "    ID = f'key{total.index(max(total)) + 1}'\n",
    "    return ID # Returns the key that has the highest total\n",
    "\n",
    "def lowToHigh(currentB, previousB):\n",
    "    passed = False\n",
    "    if currentB and not previousB:\n",
    "        passed = True\n",
    "    return passed\n",
    "\n",
    "# Define the distortion coefficients\n",
    "k1 = -0.8  # pincushion distortion\n",
    "k2 = 0.0\n",
    "k3 = 0.0\n",
    "p1 = 0.0\n",
    "p2 = 0.0\n",
    "dist_coeffs = np.array([k1, k2, k3, p1, p2], dtype=np.float32)\n",
    "    \n",
    "def distortImage(img):\n",
    "    # Distortion values\n",
    "    \n",
    "    # Define the camera matrix\n",
    "    focal_length = 300\n",
    "    center_x = img.shape[1] / 2\n",
    "    center_y = img.shape[0] / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "    \n",
    "    # Apply pincushion distortion to the image\n",
    "    img_distorted = cv2.undistort(img, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    return img_distorted\n",
    "\n",
    "# Finding peak element in a 2D Array.\n",
    "def findPeakGrid(mat):\n",
    "    stcol = 0\n",
    "    endcol = len(mat[0]) - 1; # Starting po  end po of Search Space\n",
    " \n",
    "    while (stcol <= endcol):  # Bin Search Condition\n",
    " \n",
    "        midcol = stcol + int((endcol - stcol) / 2)\n",
    "        ansrow = 0;\n",
    "        # \"ansrow\" To keep the row number of global Peak\n",
    "        # element of a column\n",
    " \n",
    "        # Finding the row number of Global Peak element in\n",
    "        # Mid Column.\n",
    "        for r in range(len(mat)):\n",
    "            ansrow = r if mat[r][midcol] >= mat[ansrow][midcol] else ansrow;\n",
    "         \n",
    " \n",
    "        # Finding next Search space will be left or right\n",
    "        valid_left =  midcol - 1 >= stcol and mat[ansrow][midcol - 1] > mat[ansrow][midcol];\n",
    "        valid_right = midcol + 1 <= endcol and mat[ansrow][midcol + 1] > mat[ansrow][midcol];\n",
    " \n",
    "        # if we're at Peak Element\n",
    "        if (not valid_left and not valid_right) :\n",
    "            return [ ansrow, midcol ];\n",
    "         \n",
    " \n",
    "        elif (valid_right):\n",
    "            stcol = midcol  + 1; # move the search space in right\n",
    "        else:\n",
    "            endcol = midcol  - 1; # move the search space in left\n",
    "     \n",
    "    return [ -1, -1 ];\n",
    "\n",
    "def xyPeak(mat):\n",
    "    peak = findPeakGrid(mat)\n",
    "    return [peak[0]-crop_size/2,peak[1]-crop_size/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d25cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask values to be edited\n",
    "# Y, X, radius_squared = -20, 135, 1000\n",
    "Y, X, radius_squared, radius = 7, 16, 60, 10\n",
    "crop_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486a3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start camera\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# # cap = cv2.VideoCapture(1 + cv2.CAP_DSHOW)\n",
    "\n",
    "url = \"http://10.209.172.96:8080/video\"\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# # Inside\n",
    "# # cap.set(cv2.CAP_PROP_EXPOSURE, -2) \n",
    "# # cap.set(cv2.CAP_PROP_BRIGHTNESS, 230) \n",
    "# # cap.set(cv2.CAP_PROP_CONTRAST, 255) \n",
    "# # cap.set(cv2.CAP_PROP_SHARPNESS, 130) \n",
    "# # cap.set(cv2.CAP_PROP_FOCUS, 18) \n",
    "# # cap.set(cv2.CAP_PROP_GAIN, 60) \n",
    "# # cap.set(cv2.CAP_PROP_TILT, -1) \n",
    "# # cap.set(cv2.CAP_PROP_PAN, 0) \n",
    "# # cap.set(cv2.CAP_PROP_ZOOM, 500) \n",
    "\n",
    "# # Darkness\n",
    "# # cap.set(cv2.CAP_PROP_EXPOSURE, -2) \n",
    "# # cap.set(cv2.CAP_PROP_BRIGHTNESS, 236) \n",
    "# # cap.set(cv2.CAP_PROP_CONTRAST, 250) \n",
    "# # cap.set(cv2.CAP_PROP_SHARPNESS, 141) \n",
    "# # cap.set(cv2.CAP_PROP_FOCUS, 18) \n",
    "# # cap.set(cv2.CAP_PROP_GAIN, 255) \n",
    "# # cap.set(cv2.CAP_PROP_TILT, 0) \n",
    "# # cap.set(cv2.CAP_PROP_PAN, 0) \n",
    "# # cap.set(cv2.CAP_PROP_ZOOM, 390) \n",
    "\n",
    "\n",
    "# # Darkness 2.0\n",
    "# cap.set(cv2.CAP_PROP_EXPOSURE, -2) \n",
    "# cap.set(cv2.CAP_PROP_BRIGHTNESS, 80) \n",
    "# cap.set(cv2.CAP_PROP_CONTRAST, 255) \n",
    "# cap.set(cv2.CAP_PROP_SHARPNESS, 110) \n",
    "# cap.set(cv2.CAP_PROP_FOCUS, 18) \n",
    "# cap.set(cv2.CAP_PROP_GAIN, 220) \n",
    "# cap.set(cv2.CAP_PROP_TILT, 0) \n",
    "# cap.set(cv2.CAP_PROP_PAN, 0) \n",
    "# cap.set(cv2.CAP_PROP_ZOOM, 390) \n",
    "\n",
    "# cap.set(cv2.CAP_PROP_SETTINGS, 1) # Set settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "#    ret, frame = cap.read()\n",
    "#    cv2.imshow(\"test\", frame)\n",
    "#        \n",
    "#    key = cv2.waitKey(1)\n",
    "#    if key == ord(\"q\"):\n",
    "#        break\n",
    "#\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7366e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d22c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493ef396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkrhi\\AppData\\Local\\Temp\\ipykernel_5512\\2153684344.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5512\\190167519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Convert the frame to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Open the keyboard using selenium\n",
    "driver = startDriver()\n",
    "keyboard = getToDarkness(driver)\n",
    "\n",
    "previousClicked = False\n",
    "firstRun = True\n",
    "firstImageCaptured = False\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame = frame[0:crop_size, 0:crop_size]\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    while firstRun:\n",
    "        first_gray = gray\n",
    "        firstRun = False\n",
    "    \n",
    "    # Capture background frame when user presses 'f'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "        first_gray = gray\n",
    "        keyboard = getToScreener(driver)\n",
    "        firstImageCaptured = True\n",
    "\n",
    "    # Display the original and transformed frames\n",
    "    cv2.imshow('Current', frame)\n",
    "    cv2.imshow('Magnitude Spectrum', power_spectrum(FFT(gray)))\n",
    "    \n",
    "    # Difference in images\n",
    "    diff_img = cv2.absdiff(gray, first_gray)\n",
    "    dist_img = distortImage(diff_img)\n",
    "    \n",
    "#     thresh = cv2.threshold(diff_img, 25, 1, cv2.THRESH_BINARY)[1]\n",
    "#     diff_img2 = cv2.threshold(diff_img, 0, 100, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Display the difference of the two images and its fourier transform\n",
    "    cv2.imshow('Difference', dist_img)\n",
    "    cv2.imshow('FFT of Difference', power_spectrum(FFT(dist_img)))\n",
    "    \n",
    "    fft_diff = FFT(dist_img)\n",
    "#     only_mask = maskSquare(fft_diff, radius, X, Y)\n",
    "#     peak = xyPeak(only_mask)\n",
    "#     masked_img = maskDots(fft_diff, len(gray), len(gray[0]), peak[0], peak[1], radius_squared)\n",
    "\n",
    "    #masked_img = maskSquare(fft_diff, radius, X, Y)\n",
    "    #masked_img = fft_diff\n",
    "    #final_img = inverse_FFT(masked_img)\n",
    "    \n",
    "    # Display the masked image and fourier\n",
    "    #cv2.imshow('Final Image', final_img)\n",
    "    #cv2.imshow('FFT of mask', power_spectrum(masked_img))\n",
    "    \n",
    "    # Tell if plane is interacted with and which key is pressed\n",
    "#     if firstImageCaptured:\n",
    "#         currentClicked = planeInteraction(power_spectrum(FFT(gray)), X, Y)\n",
    "#         if currentClicked:\n",
    "#             #print((keyAreaPressed(final_img)), end=\"\\r\")\n",
    "#             if lowToHigh(currentClicked, previousClicked):\n",
    "#                 keyboard.find_element(By.ID, keyAreaPressed(final_img)).click()\n",
    "#                 #print(currentClicked, previousClicked)\n",
    "#         previousClicked = currentClicked\n",
    "\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "keyboard.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d53fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d28e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

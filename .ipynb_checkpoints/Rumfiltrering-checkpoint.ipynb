{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e3b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fftpack import ifft2\n",
    "import pandas as pd\n",
    "import time\n",
    "# import websocket\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "# import mouse\n",
    "from rotpy.system import SpinSystem\n",
    "from rotpy.camera import CameraList\n",
    "from rotpy.camera_nodes import CameraNodes\n",
    "from numpy import unravel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48dd1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startDriver():\n",
    "    \"\"\"Starts the WebDriver (Chrome) and returns the driver object.\"\"\"\n",
    "    driver = webdriver.Chrome(executable_path=r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n",
    "    return driver\n",
    "\n",
    "def getToScreener(driver):\n",
    "    \"\"\"Navigates the WebDriver to the specified URL and returns the driver object.\"\"\"\n",
    "    # URL = 'file:///C:/Users/Bruger/Documents/GitHub/B.Sc.-Touch-Free-Interaction/Website/index.html'\n",
    "    URL = 'file:///C:/Users/mkrhi/OneDrive/Dokumenter/GitHub/Touch-Free-Interaction/Website/index.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def getToDarkness(driver):\n",
    "    \"\"\"Navigates the WebDriver to the specified URL and returns the driver object.\"\"\"\n",
    "    URL = 'file:///C:/Users/mkrhi/OneDrive/Dokumenter/GitHub/Touch-Free-Interaction/Website/black.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def clickNumber(number, driver):\n",
    "    \"\"\"Clicks the specified number on a web page using the WebDriver.\"\"\"\n",
    "    button = driver.find_element(By.ID, f'key{number}')\n",
    "    button.click()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    \"\"\"Prints the received message through WebSocket.\"\"\"\n",
    "    print(message)\n",
    "\n",
    "def power_spectrum(fft):\n",
    "    \"\"\"Returns the power spectrum of the 2D-Fourier Transform.\"\"\"\n",
    "    return np.abs(fft)**2\n",
    "\n",
    "def FFT(image):\n",
    "    \"\"\"Returns the fast Fourier transform after it is centered.\"\"\"\n",
    "    fft = np.fft.fft2(image, s=None, axes=(-2, -1), norm=None)\n",
    "    fft = np.fft.fftshift(fft, axes=None)\n",
    "    return fft\n",
    "\n",
    "def inverse_FFT(pwr_spectrum):\n",
    "    \"\"\"Computes the inverse Fourier transform of the power spectrum.\"\"\"\n",
    "    fft_array = np.fft.ifftshift(pwr_spectrum, axes=None)\n",
    "    img = np.fft.ifft2(fft_array)\n",
    "    #img = ifft2(fft_array)\n",
    "    #img = np.real(img)\n",
    "    #img = (img - np.min(img)) * (255 / (np.max(img) - np.min(img)))\n",
    "    return np.abs(img.astype(np.uint8)) ** 2\n",
    "\n",
    "def maskDots(fft_img, X, Y, radius_squared):\n",
    "    \"\"\"Masks the dots in the FFT image.\"\"\"\n",
    "    r1 = (np.arange(crop_size)[:, None] - Y - crop_size/2) ** 2 + (np.arange(crop_size) - X - crop_size/2) ** 2\n",
    "    r2 = (np.arange(crop_size)[:, None] + Y - crop_size/2) ** 2 + (np.arange(crop_size) + X - crop_size/2) ** 2\n",
    "    mask = np.logical_and(r1 > radius_squared, r2 > radius_squared)\n",
    "    fft_img[mask] = 0\n",
    "    fft_copy = fft_img.copy()\n",
    "    return fft_copy\n",
    "\n",
    "def maskLine(fft_img, X, Y, radius_squared):\n",
    "    \"\"\"Masks the line in the FFT image.\"\"\"\n",
    "    r = []\n",
    "    for i in range(10):\n",
    "        r.append((np.arange(crop_size)[:, None] - Y + (2*Y/10*i) - crop_size/2) ** 2 + (np.arange(crop_size) - X + (2*X/10*i) - crop_size/2) ** 2)\n",
    "    center = (np.arange(crop_size)[:, None] - crop_size/2) ** 2 + (np.arange(crop_size) - crop_size/2) ** 2\n",
    "    mask = r[0] > radius_squared\n",
    "    for i in range(9):\n",
    "        if i not in [3, 4, 5, 6]:\n",
    "            mask = np.logical_and(mask, r[i+1] > radius_squared)\n",
    "    fft_img[mask] = 0\n",
    "    fft_copy = fft_img.copy()\n",
    "    return fft_copy\n",
    "\n",
    "def maskSquare(a, radius, X, Y):\n",
    "    \"\"\"Masks the square in the FFT image.\"\"\"\n",
    "    X = int(X + crop_size/2)\n",
    "    Y = int(Y + crop_size/2)\n",
    "    b = np.array(a.copy(), dtype=np.uint8)\n",
    "    return b[Y - radius:Y + radius, X - radius:X + radius]\n",
    "\n",
    "def mask(fft_img, height, width, X, Y, radius_squared):\n",
    "    \"\"\"Masks the FFT image.\"\"\"\n",
    "    return maskDots(fft_img, height, width, X, Y, radius_squared)\n",
    "\n",
    "def planeInteraction(peak):\n",
    "    \"\"\"Checks if the plane interaction meets a condition.\"\"\"\n",
    "    value = findPeakGrid(peak)\n",
    "    return value > 2 * 10 ** 7, value\n",
    "\n",
    "def keyAreaPressed(img):\n",
    "    \"\"\"Returns the pressed key based on the image.\"\"\"\n",
    "    keys, points = 3, 10\n",
    "    height, width = len(img) / keys, len(img[0]) / keys\n",
    "    total = []\n",
    "    for h in range(keys-1, -1, -1):\n",
    "        for w in range(keys):\n",
    "            value = 0\n",
    "            for i in range(points):\n",
    "                for j in range(points):\n",
    "                    value += img[int(h*height + height/4 + height/2*(i+1)/points)][int(w*width + width/4 + width/2*(i+1)/points)]\n",
    "            total.append(value)\n",
    "    multiply_factor = [1.4, 1, 1.6, 1.5, 1.4, 1.4, 1.6, 1.1, 1.2] # Amplifying each key intensity accorting to testing\n",
    "    for i in range(len(total)):\n",
    "        total[i] = total[i] * multiply_factor[i]\n",
    "    ID = f'key{total.index(max(total))+1}'\n",
    "    return ID\n",
    "\n",
    "def lowToHigh(currentB, previousB):\n",
    "    \"\"\"Checks if a condition is met by comparing two values.\"\"\"\n",
    "    passed = False\n",
    "    if currentB and not previousB:\n",
    "        passed = True\n",
    "    return passed\n",
    "\n",
    "k1 = -0.7  # pincushion distortion\n",
    "k2 = 0.0\n",
    "k3 = 0.0\n",
    "p1 = 0.0\n",
    "p2 = 0.0\n",
    "dist_coeffs = np.array([k1, k2, k3, p1, p2], dtype=np.float32)\n",
    "\n",
    "def distortImage(img):\n",
    "    \"\"\"Distorts the image.\"\"\"\n",
    "    focal_length = 300\n",
    "    center_x = img.shape[1] / 2\n",
    "    center_y = img.shape[0] / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "    img_distorted = cv2.undistort(img, camera_matrix, dist_coeffs)\n",
    "    return img_distorted\n",
    "\n",
    "def findPeakGrid(a):\n",
    "    \"\"\"Finds the peak value in a grid.\"\"\"\n",
    "    size = len(a)\n",
    "    b = np.asarray(a)\n",
    "    return b.max()\n",
    "\n",
    "def xyPeak(a):\n",
    "    \"\"\"Returns the X and Y coordinates of the peak in a grid.\"\"\"\n",
    "    peak = findPeakGrid(a)\n",
    "    return [peak[0]+X-radius, peak[1]+Y-radius]\n",
    "\n",
    "def cameraInDarkness(cap):\n",
    "    \"\"\"Sets camera settings for darkness conditions.\"\"\"\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -2)\n",
    "    cap.set(cv2.CAP_PROP_BRIGHTNESS, 104)\n",
    "    cap.set(cv2.CAP_PROP_SATURATION, 0)\n",
    "    cap.set(cv2.CAP_PROP_CONTRAST, 255)\n",
    "    cap.set(cv2.CAP_PROP_SHARPNESS, 165)\n",
    "    cap.set(cv2.CAP_PROP_FOCUS, 18)\n",
    "    cap.set(cv2.CAP_PROP_GAIN, 255)\n",
    "    cap.set(cv2.CAP_PROP_TILT, 0)\n",
    "    cap.set(cv2.CAP_PROP_PAN, 0)\n",
    "    cap.set(cv2.CAP_PROP_ZOOM, 390)\n",
    "\n",
    "def cameraInLight(cap):\n",
    "    \"\"\"Sets camera settings for light conditions.\"\"\"\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -2)\n",
    "    cap.set(cv2.CAP_PROP_BRIGHTNESS, 230)\n",
    "    cap.set(cv2.CAP_PROP_CONTRAST, 255)\n",
    "    cap.set(cv2.CAP_PROP_SHARPNESS, 130)\n",
    "    cap.set(cv2.CAP_PROP_FOCUS, 18)\n",
    "    cap.set(cv2.CAP_PROP_GAIN, 60)\n",
    "    cap.set(cv2.CAP_PROP_TILT, -1)\n",
    "    cap.set(cv2.CAP_PROP_PAN, 0)\n",
    "    cap.set(cv2.CAP_PROP_ZOOM, 500)\n",
    "    return cap\n",
    "\n",
    "def getComputerCamera():\n",
    "    \"\"\"Returns the computer's camera object.\"\"\"\n",
    "    return cv2.VideoCapture(0)\n",
    "\n",
    "def getWebCam():\n",
    "    \"\"\"Returns the webcam object.\"\"\"\n",
    "    return cv2.VideoCapture(1 + cv2.CAP_DSHOW)\n",
    "\n",
    "def changeCameraSetting(cap):\n",
    "    \"\"\"Changes the camera settings.\"\"\"\n",
    "    cap.set(cv2.CAP_PROP_SETTINGS, 1)\n",
    "    return cap\n",
    "\n",
    "def captureImage(camera):\n",
    "    \"\"\"Captures an image from the camera.\"\"\"\n",
    "    camera.begin_acquisition()\n",
    "    image_cam = camera.get_next_image(timeout=5)\n",
    "    image = image_cam.deep_copy_image(image_cam)\n",
    "    image_data = image_cam.get_image_data()\n",
    "    image_height = image.get_height()\n",
    "    image_width = image.get_width()\n",
    "    image_cam.release()\n",
    "    camera.end_acquisition()\n",
    "    numpy_array = np.array(image_data)\n",
    "    reshaped_array = numpy_array.reshape((image_height, image_width))\n",
    "    reshaped_array = reshaped_array\n",
    "    return resizeImg(reshaped_array)\n",
    "\n",
    "def initCamera():\n",
    "    \"\"\"Initializes the camera.\"\"\"\n",
    "    system = SpinSystem()\n",
    "    cameras = CameraList.create_from_system(system, update_cams=True, update_interfaces=True)\n",
    "    camera = cameras.create_camera_by_index(0)\n",
    "    camera.init_cam()\n",
    "#     camera.camera_nodes.ExposureAuto.is_available()\n",
    "#     print(camera.camera_nodes.Gain.get_entries_names())\n",
    "#     camera.camera_nodes.GainAuto.set_node_value_from_str('Off')\n",
    "#     camera.camera_nodes.AcquisitionFrameRateEnable.set_node_value_from_str('true')\n",
    "#     camera.camera_nodes.AcquisitionFrameRate.set_node_value(50)\n",
    "#     camera.camera_nodes.Gain.set_node_value(23.9)\n",
    "#     camera.camera_nodes.GainAuto.set_node_value_from_str('Continuous')\n",
    "#     camera.camera_nodes.ExposureAuto.get_entries_names()\n",
    "    return camera\n",
    "\n",
    "def resizeImg(img):\n",
    "    \"\"\"Resizes the image.\"\"\"\n",
    "    smallest_axis = min(len(img), len(img[0]))\n",
    "    img = img[100:smallest_axis-100, 100:smallest_axis-100]\n",
    "    dim = (crop_size, crop_size)\n",
    "    resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e566d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = initCamera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d25cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask values to be edited\n",
    "Y, X, radius = 7, 13, 6\n",
    "radius_squared = int(radius ** 2)\n",
    "crop_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486a3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Camera\n",
    "# cap = getWebCam()\n",
    "# cameraInDarkness(cap)\n",
    "# changeCameraSetting(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ef396",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkrhi\\AppData\\Local\\Temp\\ipykernel_18068\\126928415.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n",
      "C:\\Users\\mkrhi\\AppData\\Local\\Temp\\ipykernel_18068\\126928415.py:45: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.abs(img.astype(np.uint8)) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355640489.36504354\r"
     ]
    }
   ],
   "source": [
    "# Open the keyboard using selenium\n",
    "driver = startDriver()\n",
    "keyboard = getToDarkness(driver)\n",
    "\n",
    "previousClicked = False\n",
    "firstRun = True\n",
    "firstImageCaptured = False\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "#     frame = frame[0:crop_size, 0:crop_size]\n",
    "\n",
    "#     # Convert the frame to grayscale\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while firstRun:\n",
    "        camera = initCamera()\n",
    "        first_gray = captureImage(camera)\n",
    "        firstRun = False\n",
    "        \n",
    "    gray = captureImage(camera)\n",
    "    \n",
    "    # Capture background frame when user presses 'f'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "        first_gray = gray\n",
    "        keyboard = getToScreener(driver)\n",
    "        firstImageCaptured = True\n",
    "\n",
    "    # Difference in images\n",
    "    diff_img = cv2.absdiff(gray, first_gray)\n",
    "    dist_img = distortImage(gray)\n",
    "#     dist_img = diff_img\n",
    "\n",
    "    \n",
    "    fft_dist = FFT(dist_img)\n",
    "    #only_mask = maskSquare(fft_dist, radius, X, Y)\n",
    "    #peak = xyPeak(only_mask)\n",
    "    \n",
    "    masked_img = maskDots(fft_dist, X, Y, radius_squared)\n",
    "    final_img = inverse_FFT(masked_img)\n",
    "    \n",
    "    #img1 = np.concatenate((gray,power_spectrum(FFT(gray))),axis=0)\n",
    "    #img2 = np.concatenate((dist_img,power_spectrum(FFT(dist_img))),axis=0)\n",
    "    #img3 = np.concatenate((final_img,power_spectrum(masked_img)),axis=0)\n",
    "    #img_total = np.concatenate((img1,img2,img3),axis=1)\n",
    "    #cv2.imshow('allWindows', img_total)\n",
    "    \n",
    "    cv2.imshow(\"gray\",gray)\n",
    "    cv2.imshow(\"power_spectrum\",power_spectrum(FFT(gray)))\n",
    "    cv2.imshow(\"difference\",dist_img)\n",
    "    cv2.imshow(\"dist_power\",power_spectrum(fft_dist))\n",
    "    cv2.imshow(\"final_img\",final_img)\n",
    "    ps_mask = power_spectrum(masked_img)\n",
    "    cv2.imshow(\"masked_power\",ps_mask)\n",
    "    \n",
    "    \n",
    "    # Tell if plane is interacted with and which key is pressed\n",
    "    if firstImageCaptured:\n",
    "        currentClicked = planeInteraction(ps_mask)[0]\n",
    "        print(planeInteraction(ps_mask)[1], end=\"\\r\")\n",
    "        if currentClicked:\n",
    "            #print((keyAreaPressed(final_img)), end=\"\\r\")\n",
    "            if lowToHigh(currentClicked, previousClicked):\n",
    "                keyboard.find_element(By.ID, keyAreaPressed(final_img)).click()\n",
    "                #print(currentClicked, previousClicked)\n",
    "                print(keyAreaPressed(final_img), end=\"\\r\")\n",
    "        previousClicked = currentClicked\n",
    "\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "camera.deinit_cam()\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "keyboard.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

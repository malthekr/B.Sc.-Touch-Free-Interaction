{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e3b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fftpack import ifft2\n",
    "import pandas as pd\n",
    "import time\n",
    "# import websocket\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "# import mouse\n",
    "from rotpy.system import SpinSystem\n",
    "from rotpy.camera import CameraList\n",
    "from numpy import unravel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48dd1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startDriver():\n",
    "    \"\"\"Starts the WebDriver (Chrome) and returns the driver object.\"\"\"\n",
    "    driver = webdriver.Chrome(executable_path=r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n",
    "    return driver\n",
    "\n",
    "def getToScreener(driver):\n",
    "    \"\"\"Navigates the WebDriver to the specified URL and returns the driver object.\"\"\"\n",
    "    URL = 'file:///C:/Users/Bruger/Documents/GitHub/B.Sc.-Touch-Free-Interaction/Website/index.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def getToDarkness(driver):\n",
    "    \"\"\"Navigates the WebDriver to the specified URL and returns the driver object.\"\"\"\n",
    "    URL = 'file:///C:/Users/Bruger/Documents/GitHub/B.Sc.-Touch-Free-Interaction/Website/black.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def clickNumber(number, driver):\n",
    "    \"\"\"Clicks the specified number on a web page using the WebDriver.\"\"\"\n",
    "    button = driver.find_element(By.ID, f'key{number}')\n",
    "    button.click()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    \"\"\"Prints the received message through WebSocket.\"\"\"\n",
    "    print(message)\n",
    "\n",
    "def power_spectrum(fft):\n",
    "    \"\"\"Returns the power spectrum of the 2D-Fourier Transform.\"\"\"\n",
    "    return np.abs(fft)**2\n",
    "\n",
    "def FFT(image):\n",
    "    \"\"\"Returns the fast Fourier transform after it is centered.\"\"\"\n",
    "    fft = np.fft.fft2(image, s=None, axes=(-2, -1), norm=None)\n",
    "    fft = np.fft.fftshift(fft, axes=None)\n",
    "    return fft\n",
    "\n",
    "def inverse_FFT(pwr_spectrum):\n",
    "    \"\"\"Computes the inverse Fourier transform of the power spectrum.\"\"\"\n",
    "    fft_array = np.fft.ifftshift(pwr_spectrum, axes=None)\n",
    "    img = ifft2(fft_array)\n",
    "    img = np.real(img)\n",
    "    img = (img - np.min(img)) * (255 / (np.max(img) - np.min(img)))\n",
    "    return np.abs(img.astype(np.uint8)) ** 2\n",
    "\n",
    "def maskDots(fft_img, X, Y, radius_squared):\n",
    "    \"\"\"Masks the dots in the FFT image.\"\"\"\n",
    "    r1 = (np.arange(crop_size)[:, None] - Y - crop_size/2) ** 2 + (np.arange(crop_size) - X - crop_size/2) ** 2\n",
    "    r2 = (np.arange(crop_size)[:, None] + Y - crop_size/2) ** 2 + (np.arange(crop_size) + X - crop_size/2) ** 2\n",
    "    mask = np.logical_and(r1 > radius_squared, r2 > radius_squared)\n",
    "    fft_img[mask] = 0\n",
    "    fft_copy = fft_img.copy()\n",
    "    return fft_copy\n",
    "\n",
    "def maskLine(fft_img, X, Y, radius_squared):\n",
    "    \"\"\"Masks the line in the FFT image.\"\"\"\n",
    "    r = []\n",
    "    for i in range(10):\n",
    "        r.append((np.arange(crop_size)[:, None] - Y + (2*Y/10*i) - crop_size/2) ** 2 + (np.arange(crop_size) - X + (2*X/10*i) - crop_size/2) ** 2)\n",
    "    center = (np.arange(crop_size)[:, None] - crop_size/2) ** 2 + (np.arange(crop_size) - crop_size/2) ** 2\n",
    "    mask = r[0] > radius_squared\n",
    "    for i in range(9):\n",
    "        if i not in [3, 4, 5, 6]:\n",
    "            mask = np.logical_and(mask, r[i+1] > radius_squared)\n",
    "    fft_img[mask] = 0\n",
    "    fft_copy = fft_img.copy()\n",
    "    return fft_copy\n",
    "\n",
    "def maskSquare(a, radius, X, Y):\n",
    "    \"\"\"Masks the square in the FFT image.\"\"\"\n",
    "    X = int(X + crop_size/2)\n",
    "    Y = int(Y + crop_size/2)\n",
    "    b = np.array(a.copy(), dtype=np.uint8)\n",
    "    return b[Y - radius:Y + radius, X - radius:X + radius]\n",
    "\n",
    "def mask(fft_img, height, width, X, Y, radius_squared):\n",
    "    \"\"\"Masks the FFT image.\"\"\"\n",
    "    return maskDots(fft_img, height, width, X, Y, radius_squared)\n",
    "\n",
    "def planeInteraction(peak):\n",
    "    \"\"\"Checks if the plane interaction meets a condition.\"\"\"\n",
    "    value = abs(fft_dist[int(peak[1]+crop_size/2)][int(peak[0]+crop_size/2)])\n",
    "    return value > 1800, value\n",
    "\n",
    "def keyAreaPressed(img):\n",
    "    \"\"\"Returns the pressed key based on the image.\"\"\"\n",
    "    keys, points = 3, 10\n",
    "    height, width = len(img) / keys, len(img[0]) / keys\n",
    "    total = []\n",
    "    for h in range(keys-1, -1, -1):\n",
    "        for w in range(keys):\n",
    "            value = 0\n",
    "            for i in range(points):\n",
    "                for j in range(points):\n",
    "                    value += img[int(h*height + height/4 + height/2*(i+1)/points)][int(w*width + width/4 + width/2*(i+1)/points)]\n",
    "            total.append(value)\n",
    "    ID = f'key{total.index(max(total))+1}'\n",
    "    return ID\n",
    "\n",
    "def lowToHigh(currentB, previousB):\n",
    "    \"\"\"Checks if a condition is met by comparing two values.\"\"\"\n",
    "    passed = False\n",
    "    if currentB and not previousB:\n",
    "        passed = True\n",
    "    return passed\n",
    "\n",
    "k1 = -0.4  # pincushion distortion\n",
    "k2 = 0.0\n",
    "k3 = 0.0\n",
    "p1 = 0.0\n",
    "p2 = 0.0\n",
    "dist_coeffs = np.array([k1, k2, k3, p1, p2], dtype=np.float32)\n",
    "\n",
    "def distortImage(img):\n",
    "    \"\"\"Distorts the image.\"\"\"\n",
    "    focal_length = 300\n",
    "    center_x = img.shape[1] / 2\n",
    "    center_y = img.shape[0] / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "    img_distorted = cv2.undistort(img, camera_matrix, dist_coeffs)\n",
    "    return img_distorted\n",
    "\n",
    "def findPeakGrid(a):\n",
    "    \"\"\"Finds the peak value in a grid.\"\"\"\n",
    "    size = len(a)\n",
    "    b = np.asarray(a)\n",
    "    return b.max()\n",
    "\n",
    "def xyPeak(a):\n",
    "    \"\"\"Returns the X and Y coordinates of the peak in a grid.\"\"\"\n",
    "    peak = findPeakGrid(a)\n",
    "    return [peak[0]+X-radius, peak[1]+Y-radius]\n",
    "\n",
    "def cameraInDarkness(cap):\n",
    "    \"\"\"Sets camera settings for darkness conditions.\"\"\"\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -2)\n",
    "    cap.set(cv2.CAP_PROP_BRIGHTNESS, 104)\n",
    "    cap.set(cv2.CAP_PROP_SATURATION, 0)\n",
    "    cap.set(cv2.CAP_PROP_CONTRAST, 255)\n",
    "    cap.set(cv2.CAP_PROP_SHARPNESS, 165)\n",
    "    cap.set(cv2.CAP_PROP_FOCUS, 18)\n",
    "    cap.set(cv2.CAP_PROP_GAIN, 255)\n",
    "    cap.set(cv2.CAP_PROP_TILT, 0)\n",
    "    cap.set(cv2.CAP_PROP_PAN, 0)\n",
    "    cap.set(cv2.CAP_PROP_ZOOM, 390)\n",
    "\n",
    "def cameraInLight(cap):\n",
    "    \"\"\"Sets camera settings for light conditions.\"\"\"\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -2)\n",
    "    cap.set(cv2.CAP_PROP_BRIGHTNESS, 230)\n",
    "    cap.set(cv2.CAP_PROP_CONTRAST, 255)\n",
    "    cap.set(cv2.CAP_PROP_SHARPNESS, 130)\n",
    "    cap.set(cv2.CAP_PROP_FOCUS, 18)\n",
    "    cap.set(cv2.CAP_PROP_GAIN, 60)\n",
    "    cap.set(cv2.CAP_PROP_TILT, -1)\n",
    "    cap.set(cv2.CAP_PROP_PAN, 0)\n",
    "    cap.set(cv2.CAP_PROP_ZOOM, 500)\n",
    "    return cap\n",
    "\n",
    "def getComputerCamera():\n",
    "    \"\"\"Returns the computer's camera object.\"\"\"\n",
    "    return cv2.VideoCapture(0)\n",
    "\n",
    "def getWebCam():\n",
    "    \"\"\"Returns the webcam object.\"\"\"\n",
    "    return cv2.VideoCapture(1 + cv2.CAP_DSHOW)\n",
    "\n",
    "def changeCameraSetting(cap):\n",
    "    \"\"\"Changes the camera settings.\"\"\"\n",
    "    cap.set(cv2.CAP_PROP_SETTINGS, 1)\n",
    "    return cap\n",
    "\n",
    "def captureImage(camera):\n",
    "    \"\"\"Captures an image from the camera.\"\"\"\n",
    "    camera.begin_acquisition()\n",
    "    image_cam = camera.get_next_image(timeout=5)\n",
    "    image = image_cam.deep_copy_image(image_cam)\n",
    "    image_data = image_cam.get_image_data()\n",
    "    image_height = image.get_height()\n",
    "    image_width = image.get_width()\n",
    "    image_cam.release()\n",
    "    camera.end_acquisition()\n",
    "    numpy_array = np.array(image_data)\n",
    "    reshaped_array = numpy_array.reshape((image_height, image_width))\n",
    "    reshaped_array = reshaped_array\n",
    "    return resizeImg(reshaped_array)\n",
    "\n",
    "def initCamera():\n",
    "    \"\"\"Initializes the camera.\"\"\"\n",
    "    system = SpinSystem()\n",
    "    cameras = CameraList.create_from_system(system, update_cams=True, update_interfaces=True)\n",
    "    camera = cameras.create_camera_by_index(0)\n",
    "    camera.init_cam()\n",
    "    return camera\n",
    "\n",
    "def resizeImg(img):\n",
    "    \"\"\"Resizes the image.\"\"\"\n",
    "    smallest_axis = min(len(img), len(img[0]))\n",
    "    img = img[100:smallest_axis-100, 100:smallest_axis-100]\n",
    "    dim = (crop_size, crop_size)\n",
    "    resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e566d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242 175 215  32  10 223 226 255]\n",
      " [188  10 103 223 176  28 128   7]\n",
      " [  5  57  11  34  72  78  59  16]\n",
      " [ 64 113 135  78 241  28  50 232]\n",
      " [249 118  48 149  97  49 176 198]\n",
      " [178  54 124 118  41  58 167 161]\n",
      " [ 47  27 193  71 195  30  73  98]\n",
      " [103 205 113 144  46 188  38  73]]\n",
      "254\n",
      "(58379.96681274647+2418.780735733661j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_7020\\3025726011.py:72: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  b = np.array(a.copy(), dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(maskSquare(fft_dist, radius, X, Y))\n",
    "print(findPeakGrid(maskSquare(fft_dist, radius, Y, X)))\n",
    "print(findPeakGrid(fft_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d25cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask values to be edited\n",
    "# Y, X, radius_squared = -20, 135, 1000\n",
    "Y, X, radius_squared, radius = 7, 13, 40, 4\n",
    "crop_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486a3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Camera\n",
    "# cap = getWebCam()\n",
    "# cameraInDarkness(cap)\n",
    "# changeCameraSetting(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493ef396",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_7020\\3162359811.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key1\n"
     ]
    },
    {
     "ename": "SpinnakerAPIException",
     "evalue": "Spinnaker: Could not start acquisition. Please try reconnecting the device. [-1003]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSpinnakerAPIException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7020\\1309234205.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcamera\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitCamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcaptureImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcamera\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mfirstRun\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7020\\3162359811.py\u001b[0m in \u001b[0;36mcaptureImage\u001b[1;34m(camera)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcaptureImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcamera\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;34m\"\"\"Captures an image from the camera.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_acquisition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mimage_cam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_cam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeep_copy_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_cam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rotpy\\camera.pyx\u001b[0m in \u001b[0;36mrotpy.camera.Camera.begin_acquisition\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rotpy\\camera.pyx\u001b[0m in \u001b[0;36mrotpy.camera.Camera.begin_acquisition\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rotpy\\_interface.pyx\u001b[0m in \u001b[0;36mrotpy._interface.raise_spin_exc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mSpinnakerAPIException\u001b[0m: Spinnaker: Could not start acquisition. Please try reconnecting the device. [-1003]"
     ]
    }
   ],
   "source": [
    "# Open the keyboard using selenium\n",
    "driver = startDriver()\n",
    "keyboard = getToDarkness(driver)\n",
    "\n",
    "previousClicked = False\n",
    "firstRun = True\n",
    "firstImageCaptured = False\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "#     frame = frame[0:crop_size, 0:crop_size]\n",
    "\n",
    "#     # Convert the frame to grayscale\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    camera = initCamera()\n",
    "    gray = captureImage(camera)\n",
    "    \n",
    "    while firstRun:\n",
    "        first_gray = gray\n",
    "        firstRun = False\n",
    "    \n",
    "    # Capture background frame when user presses 'f'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "        first_gray = gray\n",
    "        keyboard = getToScreener(driver)\n",
    "        firstImageCaptured = True\n",
    "\n",
    "    # Difference in images\n",
    "    diff_img = cv2.absdiff(gray, first_gray)\n",
    "    dist_img = distortImage(gray)\n",
    "#     dist_img = diff_img\n",
    "\n",
    "    \n",
    "    fft_dist = FFT(dist_img)\n",
    "    #only_mask = maskSquare(fft_dist, radius, X, Y)\n",
    "    #peak = xyPeak(only_mask)\n",
    "    \n",
    "    masked_img = maskDots(fft_dist, X, Y, radius_squared)\n",
    "    final_img = inverse_FFT(masked_img)\n",
    "    \n",
    "    #img1 = np.concatenate((gray,power_spectrum(FFT(gray))),axis=0)\n",
    "    #img2 = np.concatenate((dist_img,power_spectrum(FFT(dist_img))),axis=0)\n",
    "    #img3 = np.concatenate((final_img,power_spectrum(masked_img)),axis=0)\n",
    "    #img_total = np.concatenate((img1,img2,img3),axis=1)\n",
    "    #cv2.imshow('allWindows', img_total)\n",
    "    \n",
    "    cv2.imshow(\"gray\",gray)\n",
    "    cv2.imshow(\"power_spectrum\",power_spectrum(FFT(gray)))\n",
    "    cv2.imshow(\"difference\",dist_img)\n",
    "    cv2.imshow(\"dist_power\",power_spectrum(fft_dist))\n",
    "    cv2.imshow(\"final_img\",final_img)\n",
    "    cv2.imshow(\"masked_power\",power_spectrum(masked_img))\n",
    "    \n",
    "    \n",
    "    # Tell if plane is interacted with and which key is pressed\n",
    "    if firstImageCaptured:\n",
    "        currentClicked = planeInteraction([X,Y])[0]\n",
    "        #print(planeInteraction([X,Y])[1])\n",
    "        if currentClicked:\n",
    "            #print((keyAreaPressed(final_img)), end=\"\\r\")\n",
    "            if lowToHigh(currentClicked, previousClicked):\n",
    "                keyboard.find_element(By.ID, keyAreaPressed(final_img)).click()\n",
    "                #print(currentClicked, previousClicked)\n",
    "                print(keyAreaPressed(final_img))\n",
    "        previousClicked = currentClicked\n",
    "\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "camera.deinit_cam()\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "keyboard.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

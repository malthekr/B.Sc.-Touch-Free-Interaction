{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e3b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fftpack import ifft2\n",
    "import pandas as pd\n",
    "import time\n",
    "# import websocket\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "# import mouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48dd1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startDriver():\n",
    "    driver = webdriver.Chrome(executable_path = r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n",
    "    return driver\n",
    "\n",
    "def getToScreener(driver):\n",
    "    URL = 'file:///C:/Users/Bruger/Documents/GitHub/B.Sc.-Touch-Free-Interaction/Website/index.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def getToDarkness(driver):\n",
    "    URL = 'file:///C:/Users/Bruger/Documents/GitHub/B.Sc.-Touch-Free-Interaction/Website/black.html'\n",
    "    driver.get(URL)\n",
    "    return driver\n",
    "\n",
    "def clickNumber(number, driver):\n",
    "    button = driver.find_element(By.ID, f'key{number}')\n",
    "    button.click()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    print(message)\n",
    "\n",
    "def power_spectrum(fft):\n",
    "    # Returns the power spectrum of the 2D-Fourier Transform\n",
    "    return np.abs(fft)**2\n",
    "\n",
    "def FFT(image):\n",
    "    # Return the fast fourier transform after it is centered\n",
    "    fft = np.fft.fft2(image, s=None, axes=(-2, -1), norm=None)\n",
    "    fft = np.fft.fftshift(fft, axes=None)\n",
    "    return fft\n",
    "\n",
    "def inverse_FFT(pwr_spectrum):\n",
    "    # Compute the inverse Fourier transform of the power spectrum\n",
    "    fft_array = np.fft.ifftshift(pwr_spectrum, axes=None)\n",
    "    img = ifft2(fft_array)\n",
    "\n",
    "    # Take the real part of the image to remove any imaginary components\n",
    "    img = np.real(img)\n",
    "\n",
    "    # Normalize the pixel values to the range [0, 255]\n",
    "    img = (img - np.min(img)) * (255 / (np.max(img) - np.min(img)))\n",
    "\n",
    "    # Convert the pixel values to integers and return the image\n",
    "    return np.abs(img.astype(np.uint8)) ** 2\n",
    "\n",
    "def maskDots(fft_img, X, Y, radius_squared):\n",
    "    # Compute the squared distances from the circle center\n",
    "    r1 = (np.arange(crop_size)[:, None] - Y - crop_size/2) ** 2 + (np.arange(crop_size) - X - crop_size/2) ** 2\n",
    "    r2 = (np.arange(crop_size)[:, None] + Y - crop_size/2) ** 2 + (np.arange(crop_size) + X - crop_size/2) ** 2\n",
    "\n",
    "    \n",
    "    # Create a mask that is True where both distances are greater than radius ** 2\n",
    "    mask = np.logical_and(r1 > radius_squared, r2 > radius_squared)\n",
    "\n",
    "    # Apply the mask to the FFT image\n",
    "    fft_img[mask] = 0\n",
    "    \n",
    "    fft_copy = fft_img.copy()\n",
    "\n",
    "    return fft_copy\n",
    "\n",
    "def maskLine(fft_img, X, Y, radius_squared):\n",
    "    r = []\n",
    "    for i in range(10):\n",
    "        r.append((np.arange(crop_size)[:, None] - Y + (2*Y/10*i) - crop_size/2) ** 2 + (np.arange(crop_size) - X + (2*X/10*i) - crop_size/2) ** 2)\n",
    "        \n",
    "    center = (np.arange(crop_size)[:, None] - crop_size/2) ** 2 + (np.arange(crop_size) - crop_size/2) ** 2\n",
    "    # Create a mask that is True where both distances are greater than radius ** 2\n",
    "    \n",
    "    mask = r[0] > radius_squared\n",
    "    \n",
    "    for i in range(9):\n",
    "        if i not in [3,4,5,6]:\n",
    "            mask = np.logical_and(mask, r[i+1] > radius_squared)\n",
    "\n",
    "    # Apply the mask to the FFT image\n",
    "    fft_img[mask] = 0\n",
    "    \n",
    "    fft_copy = fft_img.copy()\n",
    "\n",
    "    return fft_copy\n",
    "\n",
    "def maskSquare(a, radius, X, Y):\n",
    "    X = int(X + crop_size/2)\n",
    "    Y = int(Y + crop_size/2)\n",
    "    b = np.array(a.copy(), dtype=np.uint8)\n",
    "    return b[X - radius:X + radius,Y - radius:Y + radius]\n",
    "\n",
    "def mask(fft_img, height, width, X, Y, radius_squared):\n",
    "    return maskDots(fft_img, height, width, X, Y, radius_squared)\n",
    "\n",
    "def planeInteraction(peak):\n",
    "    return fft_dist[int(peak[0]+crop_size/2)][int(peak[1]+crop_size/2)] > 200\n",
    "\n",
    "def keyAreaPressed(img):\n",
    "    # Takes image returns which key is pressed\n",
    "    keys, points = 3, 10\n",
    "    height, width = len(img)/(keys), len(img[0])/(keys) # Determines the vertical and horizontal distance moved\n",
    "        \n",
    "    total = []\n",
    "    for h in range(keys-1,-1,-1):\n",
    "        for w in range(keys):\n",
    "            value = 0\n",
    "            for i in range(points):\n",
    "                for j in range(points):\n",
    "                    # Adds the total pixel value of all points close to center of key\n",
    "                    value += img[int(h*height + height/4 + height/2*(i+1)/points)][int(w*width + width/4 + width/2*(i+1)/points)]\n",
    "            total.append(value)\n",
    "    ID = f'key{total.index(max(total))+1}'\n",
    "    return ID # Returns the key that has the highest total\n",
    "\n",
    "def lowToHigh(currentB, previousB):\n",
    "    passed = False\n",
    "    if currentB and not previousB:\n",
    "        passed = True\n",
    "    return passed\n",
    "\n",
    "# Define the distortion coefficients\n",
    "k1 = -0.8  # pincushion distortion\n",
    "k2 = 0.0\n",
    "k3 = 0.0\n",
    "p1 = 0.0\n",
    "p2 = 0.0\n",
    "dist_coeffs = np.array([k1, k2, k3, p1, p2], dtype=np.float32)\n",
    "    \n",
    "def distortImage(img):\n",
    "    # Distortion values\n",
    "    \n",
    "    # Define the camera matrix\n",
    "    focal_length = 300\n",
    "    center_x = img.shape[1] / 2\n",
    "    center_y = img.shape[0] / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "    \n",
    "    # Apply pincushion distortion to the image\n",
    "    img_distorted = cv2.undistort(img, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    return img_distorted\n",
    "\n",
    "def findPeakGrid(a):\n",
    "    size = len(a)\n",
    "    b = np.asarray(a)\n",
    "    \n",
    "    row = 0\n",
    "    column = b.argmax()\n",
    "    while column >= size:\n",
    "        column -= size\n",
    "        row += 1\n",
    "    \n",
    "    return [column,row]\n",
    "\n",
    "def xyPeak(a):\n",
    "    peak = findPeakGrid(a)\n",
    "    return [peak[0]+X-radius,peak[1]+Y-radius]\n",
    "\n",
    "def cameraInDarkness(cap):\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -2) \n",
    "    cap.set(cv2.CAP_PROP_BRIGHTNESS, 104) \n",
    "    cap.set(cv2.CAP_PROP_SATURATION, 0) \n",
    "    cap.set(cv2.CAP_PROP_CONTRAST, 255) \n",
    "    cap.set(cv2.CAP_PROP_SHARPNESS, 165) \n",
    "    cap.set(cv2.CAP_PROP_FOCUS, 18) \n",
    "    cap.set(cv2.CAP_PROP_GAIN, 255) \n",
    "    cap.set(cv2.CAP_PROP_TILT, 0) \n",
    "    cap.set(cv2.CAP_PROP_PAN, 0) \n",
    "    cap.set(cv2.CAP_PROP_ZOOM, 390) \n",
    "    \n",
    "def cameraInLight(cap):\n",
    "    cap.set(cv2.CAP_PROP_EXPOSURE, -2) \n",
    "    cap.set(cv2.CAP_PROP_BRIGHTNESS, 230) \n",
    "    cap.set(cv2.CAP_PROP_CONTRAST, 255) \n",
    "    cap.set(cv2.CAP_PROP_SHARPNESS, 130) \n",
    "    cap.set(cv2.CAP_PROP_FOCUS, 18) \n",
    "    cap.set(cv2.CAP_PROP_GAIN, 60) \n",
    "    cap.set(cv2.CAP_PROP_TILT, -1) \n",
    "    cap.set(cv2.CAP_PROP_PAN, 0) \n",
    "    cap.set(cv2.CAP_PROP_ZOOM, 500) \n",
    "    return cap\n",
    "    \n",
    "def getComputerCamera():\n",
    "    return cv2.VideoCapture(0)\n",
    "    \n",
    "def getWebCam():\n",
    "    return cv2.VideoCapture(1 + cv2.CAP_DSHOW)\n",
    "\n",
    "def changeCameraSetting(cap):\n",
    "    cap.set(cv2.CAP_PROP_SETTINGS, 1) # Set settings\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d25cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask values to be edited\n",
    "# Y, X, radius_squared = -20, 135, 1000\n",
    "Y, X, radius_squared, radius = 10, 16, 40, 4\n",
    "crop_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486a3104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 00000203212B0770>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Camera\n",
    "cap = getWebCam()\n",
    "cameraInDarkness(cap)\n",
    "changeCameraSetting(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493ef396",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_10148\\624671286.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = r\"C:\\Users\\Webdriver\\chromedriver.exe\")\n",
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_10148\\624671286.py:86: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  b = np.array(a.copy(), dtype=np.uint8)\n",
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_10148\\624671286.py:41: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  img = (img - np.min(img)) * (255 / (np.max(img) - np.min(img)))\n",
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_10148\\624671286.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  img = (img - np.min(img)) * (255 / (np.max(img) - np.min(img)))\n"
     ]
    }
   ],
   "source": [
    "# Open the keyboard using selenium\n",
    "driver = startDriver()\n",
    "keyboard = getToDarkness(driver)\n",
    "\n",
    "previousClicked = False\n",
    "firstRun = True\n",
    "firstImageCaptured = False\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[0:crop_size, 0:crop_size]\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    while firstRun:\n",
    "        first_gray = gray\n",
    "        firstRun = False\n",
    "    \n",
    "    # Capture background frame when user presses 'f'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "        first_gray = gray\n",
    "        keyboard = getToScreener(driver)\n",
    "        firstImageCaptured = True\n",
    "        \n",
    "    img1 = np.concatenate((gray,power_spectrum(FFT(gray))),axis=0)\n",
    "\n",
    "    # Difference in images\n",
    "    diff_img = cv2.absdiff(gray, first_gray)\n",
    "    dist_img = distortImage(gray)\n",
    "    \n",
    "    img2 = np.concatenate((dist_img,power_spectrum(FFT(dist_img))),axis=0)\n",
    "    \n",
    "    fft_dist = FFT(dist_img)\n",
    "    only_mask = maskSquare(fft_dist, radius, X, Y)\n",
    "    peak = xyPeak(only_mask)\n",
    "    \n",
    "    masked_img = maskDots(fft_dist, peak[0], peak[1], radius_squared)\n",
    "    final_img = inverse_FFT(masked_img)\n",
    "    \n",
    "    img3 = np.concatenate((final_img,power_spectrum(masked_img)),axis=0)\n",
    "    \n",
    "    img_total = np.concatenate((img1,img2,img3),axis=1)\n",
    "    \n",
    "    cv2.imshow('allWindows', img_total)\n",
    "    cv2.imshow(\"gray\",gray)\n",
    "    \n",
    "    \n",
    "    # Tell if plane is interacted with and which key is pressed\n",
    "    if firstImageCaptured:\n",
    "        currentClicked = planeInteraction(peak)\n",
    "        if currentClicked:\n",
    "            #print((keyAreaPressed(final_img)), end=\"\\r\")\n",
    "            if lowToHigh(currentClicked, previousClicked):\n",
    "                keyboard.find_element(By.ID, keyAreaPressed(final_img)).click()\n",
    "                #print(currentClicked, previousClicked)\n",
    "        previousClicked = currentClicked\n",
    "\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "keyboard.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16e2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81856aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5679ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
